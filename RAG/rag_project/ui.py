"""
ç”¨æˆ·ç•Œé¢æ¨¡å— - ui.py (æ”¯æŒæ£€ç´¢å™¨é€‰æ‹©ç‰ˆæœ¬)

ä½¿ç”¨Gradioåˆ›å»ºWebç•Œé¢ï¼Œæ”¯æŒï¼š
1. é€‰æ‹©ä¸åŒçš„Qwenæ¨¡å‹
2. é€‰æ‹©ä¸åŒçš„æ£€ç´¢æ–¹æ³•
3. å®æ—¶åˆ‡æ¢é…ç½®
"""

from typing import Tuple
import gradio as gr
from rag_system import RAGSystem
from config import UI_CONFIG, SYSTEM_CONFIG


def format_retrieved_docs(docs: list) -> str:
    """
    æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ç”¨äºæ˜¾ç¤º
    
    Args:
        docs: æ–‡æ¡£åˆ—è¡¨
    
    Returns:
        æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
    """
    if not docs:
        return "æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£"
    
    result = "### ğŸ“š æ£€ç´¢åˆ°çš„æ–‡æ¡£\n\n"
    
    for i, doc in enumerate(docs, 1):
        doc_id = doc.get('id', 'N/A')
        score = doc.get('score', 0.0)
        text = doc.get('text', '')[:200]
        
        result += f"**{i}. æ–‡æ¡£ {doc_id}** (ç›¸å…³åº¦: `{score:.4f}`)\n\n"
        result += f"{text}...\n\n"
        result += "---\n\n"
    
    return result


def create_gradio_interface(rag_system: RAGSystem):
    """
    åˆ›å»ºGradioç•Œé¢
    
    Args:
        rag_system: RAGç³»ç»Ÿå®ä¾‹
    
    Returns:
        Gradioåº”ç”¨å®ä¾‹
    """
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = rag_system.generator.get_available_model_names()
    
    if not available_models:
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼")
    
    # è·å–å¯ç”¨æ£€ç´¢å™¨åˆ—è¡¨
    available_retrievers = []
    if hasattr(rag_system, 'retrievers') and rag_system.retrievers:
        # å¦‚æœæœ‰å¤šä¸ªæ£€ç´¢å™¨
        available_retrievers = list(rag_system.retrievers.keys())
    else:
        # å¦‚æœåªæœ‰ä¸€ä¸ªæ£€ç´¢å™¨
        available_retrievers = [rag_system.retriever.get_name()]
    
    # åˆ¤æ–­æ˜¯å¦æœ‰å¤šä¸ªæ£€ç´¢å™¨
    has_multiple_retrievers = len(available_retrievers) > 1
    
    def query_handler(
        question: str,
        top_k: int,
        model_choice: str,
        retriever_choice: str
    ) -> Tuple[str, str, str]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            model_choice: é€‰æ‹©çš„æ¨¡å‹
            retriever_choice: é€‰æ‹©çš„æ£€ç´¢å™¨
        
        Returns:
            (ç­”æ¡ˆ, æ£€ç´¢æ–‡æ¡£, ç³»ç»Ÿä¿¡æ¯)
        """
        if not question.strip():
            return "âš ï¸ è¯·è¾“å…¥é—®é¢˜", "", "æœªæ‰§è¡ŒæŸ¥è¯¢"
        
        # åˆ‡æ¢æ£€ç´¢å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if has_multiple_retrievers and retriever_choice:
            if retriever_choice in rag_system.retrievers:
                rag_system.retriever = rag_system.retrievers[retriever_choice]
                print(f"ğŸ”„ åˆ‡æ¢æ£€ç´¢å™¨åˆ°: {retriever_choice}")
        
        # æ‰§è¡ŒRAG
        result = rag_system.answer_question(
            query=question,
            top_k=top_k,
            model_name=model_choice,
            verbose=True
        )
        
        # æ ¼å¼åŒ–è¾“å‡º
        answer = result['answer']
        docs = format_retrieved_docs(result['retrieved_docs'])
        
        # ç³»ç»Ÿä¿¡æ¯
        system_info = f"""### ğŸ“Š å½“å‰é…ç½®

- **æ£€ç´¢æ–¹æ³•**: `{result.get('retriever_used', 'Unknown')}`
- **ç”Ÿæˆæ¨¡å‹**: `{result['model_used']}`
- **æ£€ç´¢æ–‡æ¡£æ•°**: {len(result['retrieved_docs'])} ä¸ª
"""
        
        return answer, docs, system_info
    
    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(
        title="RAGé—®ç­”ç³»ç»Ÿ",
        theme=gr.themes.Soft() if UI_CONFIG["theme"] == "soft" else None
    ) as demo:
        
        # æ ‡é¢˜
        gr.Markdown(
            """
            # ğŸ¤– RAGé—®ç­”ç³»ç»Ÿ
            ### æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation)
            
            **æ”¯æŒåŠŸèƒ½**:
            - ğŸ” å¤šç§æ£€ç´¢æ–¹æ³•ï¼ˆBM25ç¨€ç–æ£€ç´¢ã€Qwen3-Embeddingå¯†é›†æ£€ç´¢ï¼‰
            - ğŸ¤– å¤šç§Qwenå¤§è¯­è¨€æ¨¡å‹
            - âš¡ å®æ—¶åˆ‡æ¢é…ç½®
            """
        )
        
        with gr.Row():
            # ========== å·¦ä¾§ï¼šè¾“å…¥å’Œé…ç½®åŒºåŸŸ ==========
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ è¾“å…¥åŒºåŸŸ")
                
                # é—®é¢˜è¾“å…¥æ¡†
                question_input = gr.Textbox(
                    label="ğŸ’¬ è¾“å…¥æ‚¨çš„é—®é¢˜",
                    placeholder="ä¾‹å¦‚: Where was Barack Obama born?",
                    lines=3
                )
                
                gr.Markdown("### âš™ï¸ ç³»ç»Ÿé…ç½®")
                
                # æ£€ç´¢å™¨é€‰æ‹©ï¼ˆé‡ç‚¹ï¼ï¼‰
                retriever_selector = gr.Dropdown(
                    choices=available_retrievers,
                    value=available_retrievers[0],
                    label="ğŸ” é€‰æ‹©æ£€ç´¢æ–¹æ³•",
                    info="é€‰æ‹©ä¸åŒçš„æ–‡æ¡£æ£€ç´¢ç®—æ³•",
                    interactive=has_multiple_retrievers  # åªæœ‰å¤šä¸ªæ—¶æ‰å¯é€‰
                )
                
                # å¦‚æœæœ‰å¤šä¸ªæ£€ç´¢å™¨ï¼Œæ˜¾ç¤ºè¯´æ˜
                if has_multiple_retrievers:
                    gr.Markdown(
                        """
                        **æ£€ç´¢æ–¹æ³•è¯´æ˜**:
                        - **BM25**: å…³é”®è¯åŒ¹é…ï¼Œé€Ÿåº¦å¿«
                        - **Qwen3-Embedding**: è¯­ä¹‰ç†è§£ï¼Œæ›´æ™ºèƒ½
                        """
                    )
                
                # æ¨¡å‹é€‰æ‹©
                model_selector = gr.Dropdown(
                    choices=available_models,
                    value=available_models[0],
                    label="ğŸ¤– é€‰æ‹©Qwenæ¨¡å‹",
                    info="é€‰æ‹©ä¸åŒå¤§å°çš„è¯­è¨€æ¨¡å‹"
                )
                
                # æ£€ç´¢å‚æ•°
                top_k_slider = gr.Slider(
                    minimum=SYSTEM_CONFIG["top_k_min"],
                    maximum=SYSTEM_CONFIG["top_k_max"],
                    value=SYSTEM_CONFIG["top_k_default"],
                    step=1,
                    label="ğŸ“š æ£€ç´¢æ–‡æ¡£æ•°é‡",
                    info="æ£€ç´¢æ›´å¤šæ–‡æ¡£å¯èƒ½æé«˜ç­”æ¡ˆè´¨é‡"
                )
                
                # æäº¤æŒ‰é’®
                submit_btn = gr.Button(
                    "ğŸš€ æäº¤æŸ¥è¯¢",
                    variant="primary",
                    size="lg"
                )
                
                # ä½¿ç”¨è¯´æ˜
                with gr.Accordion("ğŸ’¡ ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown(
                        """
                        ### å¦‚ä½•ä½¿ç”¨
                        
                        1. **è¾“å…¥é—®é¢˜**: åœ¨ä¸Šæ–¹æ–‡æœ¬æ¡†è¾“å…¥æ‚¨çš„é—®é¢˜
                        2. **é€‰æ‹©æ£€ç´¢æ–¹æ³•**: 
                           - BM25: é€‚åˆç²¾ç¡®å…³é”®è¯åŒ¹é…
                           - Qwen3-Embedding: é€‚åˆè¯­ä¹‰ç†è§£
                        3. **é€‰æ‹©æ¨¡å‹**: 
                           - 7B: è´¨é‡æœ€å¥½ï¼Œé€Ÿåº¦è¾ƒæ…¢
                           - 3B/1.5B: å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
                        4. **è°ƒæ•´å‚æ•°**: å¯é€‰è°ƒæ•´æ£€ç´¢æ–‡æ¡£æ•°é‡
                        5. **æäº¤æŸ¥è¯¢**: ç‚¹å‡»æŒ‰é’®è·å–ç­”æ¡ˆ
                        
                        ### æ€§èƒ½å¯¹æ¯”
                        
                        | æ£€ç´¢æ–¹æ³• | é€Ÿåº¦ | è¯­ä¹‰ç†è§£ | é€‚ç”¨åœºæ™¯ |
                        |---------|------|---------|---------|
                        | BM25 | âš¡âš¡âš¡ | â­â­ | ç²¾ç¡®åŒ¹é… |
                        | Qwen3-Embedding | âš¡âš¡ | â­â­â­â­â­ | è¯­ä¹‰æŸ¥è¯¢ |
                        """
                    )
            
            # ========== å³ä¾§ï¼šè¾“å‡ºåŒºåŸŸ ==========
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ’¡ è¾“å‡ºåŒºåŸŸ")
                
                # ç³»ç»Ÿä¿¡æ¯æ˜¾ç¤º
                system_info_display = gr.Markdown(
                    value=f"""### ğŸ“Š å½“å‰é…ç½®

- **æ£€ç´¢æ–¹æ³•**: `{rag_system.retriever.get_name()}`
- **ç”Ÿæˆæ¨¡å‹**: `{rag_system.generator.current_model}`
- **æ£€ç´¢æ–‡æ¡£æ•°**: {SYSTEM_CONFIG['top_k_default']} ä¸ª
"""
                )
                
                # ç­”æ¡ˆè¾“å‡º
                answer_output = gr.Textbox(
                    label="ğŸ“ ç”Ÿæˆçš„ç­”æ¡ˆ",
                    lines=8,
                    show_copy_button=True,
                    placeholder="ç­”æ¡ˆå°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                )
                
                # æ£€ç´¢æ–‡æ¡£è¾“å‡ºï¼ˆå¯æŠ˜å ï¼‰
                with gr.Accordion("ğŸ“š æ£€ç´¢åˆ°çš„æ–‡æ¡£", open=True):
                    docs_output = gr.Markdown(
                        value="æ£€ç´¢ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                    )
        
        # ========== ç»‘å®šäº‹ä»¶ ==========
        submit_btn.click(
            fn=query_handler,
            inputs=[
                question_input,
                top_k_slider,
                model_selector,
                retriever_selector
            ],
            outputs=[
                answer_output,
                docs_output,
                system_info_display
            ]
        )
        
        # æ”¯æŒå›è½¦æäº¤
        question_input.submit(
            fn=query_handler,
            inputs=[
                question_input,
                top_k_slider,
                model_selector,
                retriever_selector
            ],
            outputs=[
                answer_output,
                docs_output,
                system_info_display
            ]
        )
        
        # ========== ç¤ºä¾‹é—®é¢˜ ==========
        gr.Examples(
            examples=[
                ["Where was Barack Obama born?"],
                ["What is the capital of France?"],
                ["Who wrote Romeo and Juliet?"],
                ["What are the causes of climate change?"],
            ],
            inputs=[question_input],
            label="ğŸ“Œ ç¤ºä¾‹é—®é¢˜ï¼ˆç‚¹å‡»è‡ªåŠ¨å¡«å……ï¼‰"
        )
        
        # ========== åº•éƒ¨ä¿¡æ¯ ==========
        gr.Markdown(
            f"""
            ---
            ### ğŸ“Š ç³»ç»Ÿä¿¡æ¯
            
            - **å¯ç”¨æ£€ç´¢å™¨**: {len(available_retrievers)} ä¸ª ({', '.join(available_retrievers)})
            - **å¯ç”¨æ¨¡å‹**: {len(available_models)} ä¸ª
            - **æ–‡æ¡£åº“å¤§å°**: 144,718 ä¸ªæ–‡æ¡£
            
            ---
            
            COMP5423 Natural Language Processing - Group Project
            """
        )
    
    return demo


def launch_interface(rag_system: RAGSystem):
    """
    å¯åŠ¨Gradioç•Œé¢
    
    Args:
        rag_system: RAGç³»ç»Ÿå®ä¾‹
    """
    print("\n" + "="*70)
    print("ğŸŒ å¯åŠ¨Webç•Œé¢")
    print("="*70)
    
    # æ˜¾ç¤ºå¯ç”¨çš„æ£€ç´¢å™¨
    if hasattr(rag_system, 'retrievers') and rag_system.retrievers:
        print(f"å¯ç”¨æ£€ç´¢å™¨: {', '.join(rag_system.retrievers.keys())}")
    else:
        print(f"å½“å‰æ£€ç´¢å™¨: {rag_system.retriever.get_name()}")
    
    # æ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹
    print(f"å¯ç”¨æ¨¡å‹: {', '.join(rag_system.generator.get_available_model_names())}")
    
    demo = create_gradio_interface(rag_system)
    
    demo.launch(
        server_name=UI_CONFIG["server_name"],
        server_port=UI_CONFIG["server_port"],
        share=UI_CONFIG["share"],
        show_error=UI_CONFIG["show_error"]
    )