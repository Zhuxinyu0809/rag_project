"""
APIç”Ÿæˆå™¨æ¨¡å— - generators/api_generator.py

é€šè¿‡APIè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆç­”æ¡ˆ
"""

from typing import List, Dict, Optional
from openai import OpenAI
from config import (
    SILICONFLOW_CONFIG,
    AVAILABLE_QWEN_MODELS,
    GENERATION_CONFIG,
    SYSTEM_CONFIG
)


class APIGenerator:
    """APIè°ƒç”¨ç”Ÿæˆå™¨ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢ï¼‰"""
    
    def __init__(
        self,
        api_key: str = None,
        base_url: str = None,
        model_config: Dict = None
    ):
        """
        åˆå§‹åŒ–APIç”Ÿæˆå™¨
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            base_url: APIåŸºç¡€URLï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            model_config: æ¨¡å‹é…ç½®å­—å…¸ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        """
        print(f"\nğŸ¤– æ­£åœ¨åˆå§‹åŒ–APIç”Ÿæˆå™¨...")
        
        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        self.api_key = api_key or SILICONFLOW_CONFIG["api_key"]
        self.base_url = base_url or SILICONFLOW_CONFIG["base_url"]
        self.model_config = model_config or AVAILABLE_QWEN_MODELS
        
        # æ£€æŸ¥APIå¯†é’¥
        if self.api_key.startswith("sk-your") or self.api_key.startswith("sk-åœ¨"):
            raise ValueError("è¯·è®¾ç½®æœ‰æ•ˆçš„APIå¯†é’¥ï¼")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # æµ‹è¯•å¹¶ç¼“å­˜æ‰€æœ‰å¯ç”¨æ¨¡å‹
        self.available_models = self._test_all_models()
        
        # è®¾ç½®é»˜è®¤æ¨¡å‹
        if self.available_models:
            self.current_model = list(self.available_models.values())[0]
            print(f"âœ… é»˜è®¤æ¨¡å‹: {self.current_model}")
        else:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼")
    
    def _test_all_models(self) -> Dict[str, str]:
        """æµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼Œè¿”å›å¯ç”¨çš„æ¨¡å‹æ˜ å°„"""
        print("\nğŸ” æ­£åœ¨æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...")
        available = {}
        
        for display_name, possible_names in self.model_config.items():
            print(f"\næµ‹è¯• {display_name}:")
            
            for model_name in possible_names:
                try:
                    print(f"   å°è¯•: {model_name}")
                    
                    # æµ‹è¯•è¯·æ±‚
                    response = self.client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "user", "content": "Hi"}],
                        max_tokens=5,
                        timeout=10
                    )
                    
                    # æˆåŠŸï¼
                    available[display_name] = model_name
                    print(f"   âœ… å¯ç”¨")
                    break
                    
                except Exception as e:
                    error_str = str(e)
                    if "does not exist" in error_str or "not found" in error_str:
                        print(f"   âŒ ä¸å­˜åœ¨")
                    else:
                        print(f"   âŒ é”™è¯¯")
                    continue
            
            if display_name not in available:
                print(f"   âš ï¸  ä¸å¯ç”¨")
        
        print(f"\nâœ… æ‰¾åˆ° {len(available)} ä¸ªå¯ç”¨æ¨¡å‹")
        return available
    
    def get_available_model_names(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹çš„æ˜¾ç¤ºåç§°åˆ—è¡¨"""
        return list(self.available_models.keys())
    
    def switch_model(self, display_name: str) -> str:
        """
        åˆ‡æ¢åˆ°æŒ‡å®šæ¨¡å‹
        
        Args:
            display_name: æ¨¡å‹çš„æ˜¾ç¤ºåç§°
        
        Returns:
            å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        if display_name in self.available_models:
            self.current_model = self.available_models[display_name]
            print(f"ğŸ”„ åˆ‡æ¢åˆ°æ¨¡å‹: {self.current_model}")
            return self.current_model
        else:
            print(f"âš ï¸  æ¨¡å‹ {display_name} ä¸å¯ç”¨ï¼Œä¿æŒå½“å‰æ¨¡å‹")
            return self.current_model
    
    def create_prompt(self, query: str, documents: List[Dict]) -> str:
        """
        åˆ›å»ºæç¤ºè¯
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            documents: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        
        Returns:
            å®Œæ•´çš„æç¤ºè¯
        """
        # æ ¼å¼åŒ–æ–‡æ¡£ä¸Šä¸‹æ–‡
        context = ""
        max_docs = SYSTEM_CONFIG["docs_for_prompt"]
        max_chars = SYSTEM_CONFIG["max_doc_chars"]
        
        for i, doc in enumerate(documents[:max_docs], 1):
            text = doc['text'][:max_chars]
            context += f"[Document {i}]\n{text}\n\n"
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        prompt = f"""Answer the question based on the provided documents.

Documents:
{context}

Question: {query}

Provide a concise answer. If the documents don't contain enough information, say "Cannot answer based on provided documents."

Answer:"""
        
        return prompt
    
    def generate(
        self,
        query: str,
        documents: List[Dict],
        model_name: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            documents: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
            model_name: è¦ä½¿ç”¨çš„æ¨¡å‹æ˜¾ç¤ºåç§°ï¼ˆNoneåˆ™ä½¿ç”¨å½“å‰æ¨¡å‹ï¼‰
        
        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        # å¦‚æœæŒ‡å®šäº†æ¨¡å‹ï¼Œå…ˆåˆ‡æ¢
        if model_name:
            self.switch_model(model_name)
        
        # åˆ›å»ºæç¤ºè¯
        prompt = self.create_prompt(query, documents)
        
        try:
            print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹ {self.current_model} ç”Ÿæˆç­”æ¡ˆ...")
            
            # è°ƒç”¨API
            response = self.client.chat.completions.create(
                model=self.current_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=GENERATION_CONFIG["max_tokens"],
                temperature=GENERATION_CONFIG["temperature"]
            )
            
            answer = response.choices[0].message.content.strip()
            print(f"   âœ… ç”ŸæˆæˆåŠŸ")
            
            return answer
            
        except Exception as e:
            error_msg = str(e)
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {error_msg[:100]}")
            return f"ç”Ÿæˆå¤±è´¥: {error_msg}"
    
    def get_name(self) -> str:
        """è¿”å›ç”Ÿæˆå™¨åç§°"""
        return f"API Generator ({self.current_model})"