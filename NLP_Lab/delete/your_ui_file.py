import gradio as gr
import json
from typing import List, Dict, Tuple, Optional

# ============================================================================
# è¿™é‡Œéœ€è¦å¯¼å…¥ä½ çš„RAGç³»ç»Ÿç»„ä»¶
# ============================================================================
# from your_retrieval_module import RetrieverSystem
# from your_generation_module import GeneratorSystem

class RAGInterface:
    """RAGç³»ç»Ÿçš„Gradioç•Œé¢å°è£…ç±»"""
    
    def __init__(self):
        # åˆå§‹åŒ–ä½ çš„æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨
        # self.retriever = RetrieverSystem()
        # self.generator = GeneratorSystem()
        
        # å¯¹è¯å†å²ï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
        self.conversation_history = []
        
    def format_retrieved_docs(self, docs: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ç”¨äºæ˜¾ç¤º"""
        if not docs:
            return "æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£"
        
        formatted = "### ğŸ“š æ£€ç´¢åˆ°çš„æ–‡æ¡£\n\n"
        for i, doc in enumerate(docs, 1):
            doc_id = doc.get('id', 'N/A')
            score = doc.get('score', 0.0)
            text = doc.get('text', '')[:200]  # åªæ˜¾ç¤ºå‰200å­—ç¬¦
            formatted += f"**æ–‡æ¡£ {i}** (ID: `{doc_id}`, ç›¸å…³åº¦: `{score:.4f}`)\n"
            formatted += f"> {text}...\n\n"
        
        return formatted
    
    def format_intermediate_steps(self, steps: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¸­é—´æ¨ç†æ­¥éª¤ï¼ˆFeature Bçš„åŠ åˆ†é¡¹ï¼‰"""
        if not steps:
            return ""
        
        formatted = "### ğŸ” ä¸­é—´æ¨ç†è¿‡ç¨‹\n\n"
        for i, step in enumerate(steps, 1):
            step_type = step.get('type', 'unknown')
            content = step.get('content', '')
            
            if step_type == 'query_rewrite':
                formatted += f"**æ­¥éª¤ {i}: æŸ¥è¯¢é‡å†™**\n"
                formatted += f"- åŸå§‹æŸ¥è¯¢: `{step.get('original', '')}`\n"
                formatted += f"- é‡å†™å: `{content}`\n\n"
            
            elif step_type == 'sub_query':
                formatted += f"**æ­¥éª¤ {i}: å­æŸ¥è¯¢åˆ†è§£**\n"
                for j, sub_q in enumerate(content, 1):
                    formatted += f"  {j}. {sub_q}\n"
                formatted += "\n"
            
            elif step_type == 'self_check':
                formatted += f"**æ­¥éª¤ {i}: è‡ªæˆ‘æ£€æŸ¥**\n"
                formatted += f"- éªŒè¯ç»“æœ: {content}\n\n"
            
            elif step_type == 'reasoning':
                formatted += f"**æ­¥éª¤ {i}: æ¨ç†è¿‡ç¨‹**\n"
                formatted += f"{content}\n\n"
        
        return formatted
    
    def single_turn_rag(
        self,
        query: str,
        retrieval_method: str,
        top_k: int,
        generation_model: str,
        show_intermediate: bool
    ) -> Tuple[str, str, str]:
        """
        å•è½®RAGæŸ¥è¯¢
        
        Returns:
            (answer, retrieved_docs, intermediate_steps)
        """
        if not query.strip():
            return "è¯·è¾“å…¥æŸ¥è¯¢é—®é¢˜", "", ""
        
        # ===== è¿™é‡Œè°ƒç”¨ä½ çš„å®é™…å®ç° =====
        # 1. æ£€ç´¢æ–‡æ¡£
        # retrieved_docs = self.retriever.search(
        #     query=query,
        #     method=retrieval_method,
        #     top_k=top_k
        # )
        
        # 2. ç”Ÿæˆç­”æ¡ˆ
        # result = self.generator.generate(
        #     query=query,
        #     documents=retrieved_docs,
        #     model=generation_model,
        #     track_steps=show_intermediate
        # )
        
        # ===== ç¤ºä¾‹è¿”å›ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…ç»“æœï¼‰ =====
        # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
        retrieved_docs = [
            {
                'id': 'doc_001',
                'score': 0.95,
                'text': 'è¿™æ˜¯ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„å†…å®¹...'
            },
            {
                'id': 'doc_002',
                'score': 0.87,
                'text': 'è¿™æ˜¯ç¬¬äºŒä¸ªç›¸å…³æ–‡æ¡£çš„å†…å®¹...'
            }
        ]
        
        # æ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆ
        answer = f"æ ¹æ®æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œé’ˆå¯¹æ‚¨çš„é—®é¢˜ã€Œ{query}ã€çš„ç­”æ¡ˆæ˜¯ï¼š[è¿™é‡Œæ˜¯ç”Ÿæˆçš„ç­”æ¡ˆ]\n\nä½¿ç”¨çš„æ£€ç´¢æ–¹æ³•: {retrieval_method}\nä½¿ç”¨çš„ç”Ÿæˆæ¨¡å‹: {generation_model}"
        
        # æ¨¡æ‹Ÿä¸­é—´æ­¥éª¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        intermediate_steps = []
        if show_intermediate:
            intermediate_steps = [
                {
                    'type': 'query_rewrite',
                    'original': query,
                    'content': f'{query} (ä¼˜åŒ–åçš„æŸ¥è¯¢)'
                },
                {
                    'type': 'reasoning',
                    'content': 'åˆ†ææŸ¥è¯¢æ„å›¾ â†’ æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ ç»¼åˆä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ'
                }
            ]
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted_docs = self.format_retrieved_docs(retrieved_docs)
        formatted_steps = self.format_intermediate_steps(intermediate_steps) if show_intermediate else ""
        
        return answer, formatted_docs, formatted_steps
    
    def multi_turn_rag(
        self,
        query: str,
        chat_history: List[Tuple[str, str]],
        retrieval_method: str,
        top_k: int,
        generation_model: str
    ) -> Tuple[List[Tuple[str, str]], str, str]:
        """
        å¤šè½®å¯¹è¯RAGï¼ˆFeature Aï¼‰
        
        Returns:
            (updated_chat_history, retrieved_docs, context_info)
        """
        if not query.strip():
            return chat_history, "", ""
        
        # ===== Feature Aå®ç°ï¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥æ£€ç´¢ =====
        # 1. é‡æ„æŸ¥è¯¢ï¼ˆèåˆå¯¹è¯å†å²ï¼‰
        # context = self._build_context(chat_history)
        # reformulated_query = self.generator.reformulate_query(query, context)
        
        # 2. æ£€ç´¢
        # retrieved_docs = self.retriever.search(
        #     query=reformulated_query,
        #     method=retrieval_method,
        #     top_k=top_k
        # )
        
        # 3. ç”Ÿæˆç­”æ¡ˆï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
        # answer = self.generator.generate_with_history(
        #     query=query,
        #     documents=retrieved_docs,
        #     history=chat_history,
        #     model=generation_model
        # )
        
        # ===== ç¤ºä¾‹è¿”å› =====
        reformulated_query = f"{query} (åŸºäºä¸Šä¸‹æ–‡é‡æ„)"
        
        retrieved_docs = [
            {
                'id': 'doc_multi_001',
                'score': 0.92,
                'text': 'è¿™æ˜¯å¤šè½®å¯¹è¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£...'
            }
        ]
        
        answer = f"æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œ{query}çš„ç­”æ¡ˆæ˜¯ï¼š[ç”Ÿæˆçš„ç­”æ¡ˆ]"
        
        # æ›´æ–°å¯¹è¯å†å²
        chat_history.append((query, answer))
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted_docs = self.format_retrieved_docs(retrieved_docs)
        context_info = f"### ğŸ”„ ä¸Šä¸‹æ–‡å¤„ç†\n\n**åŸå§‹æŸ¥è¯¢**: {query}\n\n**é‡æ„åæŸ¥è¯¢**: {reformulated_query}\n\n**å¯¹è¯è½®æ¬¡**: {len(chat_history)}"
        
        return chat_history, formatted_docs, context_info
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        return [], "", ""


def create_rag_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    rag_system = RAGInterface()
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .container {max-width: 1200px; margin: auto;}
    .output-box {border: 1px solid #ddd; border-radius: 8px; padding: 15px; background-color: #f9f9f9;}
    .highlight {background-color: #fff3cd; padding: 2px 5px; border-radius: 3px;}
    """
    
    with gr.Blocks(css=custom_css, title="RAGç³»ç»Ÿ - COMP5423é¡¹ç›®") as demo:
        
        gr.Markdown(
            """
            # ğŸ¤– æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿ
            ### COMP5423 Natural Language Processing - Group Project
            
            æœ¬ç³»ç»Ÿæ”¯æŒå¤šç§æ£€ç´¢æ–¹æ³•å’Œç”Ÿæˆæ¨¡å‹ï¼Œå¯è¿›è¡Œå•è½®æˆ–å¤šè½®å¯¹è¯å¼é—®ç­”ã€‚
            """
        )
        
        # ========== Tab 1: å•è½®RAG ==========
        with gr.Tab("ğŸ“ å•è½®é—®ç­”"):
            gr.Markdown("### åŸºç¡€RAGåŠŸèƒ½ï¼šè¾“å…¥é—®é¢˜ï¼Œæ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ç”Ÿæˆç­”æ¡ˆ")
            
            with gr.Row():
                with gr.Column(scale=1):
                    query_input = gr.Textbox(
                        label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šWhere was Barack Obama born?",
                        lines=3
                    )
                    
                    with gr.Accordion("âš™ï¸ ç³»ç»Ÿé…ç½®", open=False):
                        retrieval_method = gr.Dropdown(
                            choices=[
                                "BM25 (ç¨€ç–æ£€ç´¢)",
                                "TF-IDF (ç¨€ç–æ£€ç´¢)",
                                "E5 (å¯†é›†æ£€ç´¢)",
                                "BGE (å¯†é›†æ£€ç´¢)",
                                "GTE (å¯†é›†æ£€ç´¢)",
                                "ColBERT (å¤šå‘é‡æ£€ç´¢)",
                                "Hybrid (æ··åˆæ£€ç´¢)"
                            ],
                            value="BM25 (ç¨€ç–æ£€ç´¢)",
                            label="æ£€ç´¢æ–¹æ³•"
                        )
                        
                        top_k = gr.Slider(
                            minimum=1,
                            maximum=20,
                            value=10,
                            step=1,
                            label="æ£€ç´¢æ–‡æ¡£æ•°é‡ (Top-K)"
                        )
                        
                        generation_model = gr.Dropdown(
                            choices=[
                                "Qwen2.5-0.5B-Instruct",
                                "Qwen2.5-1.5B-Instruct",
                                "Qwen2.5-3B-Instruct",
                                "Qwen2.5-7B-Instruct"
                            ],
                            value="Qwen2.5-1.5B-Instruct",
                            label="ç”Ÿæˆæ¨¡å‹"
                        )
                        
                        show_intermediate = gr.Checkbox(
                            label="æ˜¾ç¤ºä¸­é—´æ¨ç†è¿‡ç¨‹ (Feature B)",
                            value=False
                        )
                    
                    submit_btn = gr.Button("ğŸš€ æäº¤æŸ¥è¯¢", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    answer_output = gr.Textbox(
                        label="ğŸ’¡ ç”Ÿæˆçš„ç­”æ¡ˆ",
                        lines=6,
                        elem_classes="output-box"
                    )
                    
                    retrieved_docs_output = gr.Markdown(
                        label="ğŸ“š æ£€ç´¢åˆ°çš„æ–‡æ¡£"
                    )
                    
                    intermediate_output = gr.Markdown(
                        label="ğŸ” ä¸­é—´æ¨ç†è¿‡ç¨‹",
                        visible=True
                    )
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=rag_system.single_turn_rag,
                inputs=[
                    query_input,
                    retrieval_method,
                    top_k,
                    generation_model,
                    show_intermediate
                ],
                outputs=[
                    answer_output,
                    retrieved_docs_output,
                    intermediate_output
                ]
            )
            
            # ç¤ºä¾‹é—®é¢˜
            gr.Examples(
                examples=[
                    ["Where was Barack Obama born?"],
                    ["What is the capital of France?"],
                    ["Who won the 2024 US Presidential Election?"]
                ],
                inputs=query_input,
                label="ğŸ“Œ ç¤ºä¾‹é—®é¢˜"
            )
        
        # ========== Tab 2: å¤šè½®å¯¹è¯RAG ==========
        with gr.Tab("ğŸ’¬ å¤šè½®å¯¹è¯ (Feature A)"):
            gr.Markdown("### æ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¤šè½®å¯¹è¯é—®ç­”")
            
            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯å†å²",
                        height=400
                    )
                    
                    with gr.Row():
                        multi_query_input = gr.Textbox(
                            label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                            placeholder="ç»§ç»­æé—®...",
                            scale=4
                        )
                        multi_submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
                    
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="stop")
                
                with gr.Column(scale=1):
                    with gr.Accordion("âš™ï¸ ç³»ç»Ÿé…ç½®", open=False):
                        multi_retrieval = gr.Dropdown(
                            choices=[
                                "BM25 (ç¨€ç–æ£€ç´¢)",
                                "E5 (å¯†é›†æ£€ç´¢)",
                                "BGE (å¯†é›†æ£€ç´¢)",
                                "Hybrid (æ··åˆæ£€ç´¢)"
                            ],
                            value="E5 (å¯†é›†æ£€ç´¢)",
                            label="æ£€ç´¢æ–¹æ³•"
                        )
                        
                        multi_top_k = gr.Slider(
                            minimum=1,
                            maximum=20,
                            value=10,
                            step=1,
                            label="æ£€ç´¢æ–‡æ¡£æ•°é‡"
                        )
                        
                        multi_model = gr.Dropdown(
                            choices=[
                                "Qwen2.5-1.5B-Instruct",
                                "Qwen2.5-3B-Instruct",
                                "Qwen2.5-7B-Instruct"
                            ],
                            value="Qwen2.5-3B-Instruct",
                            label="ç”Ÿæˆæ¨¡å‹"
                        )
                    
                    multi_docs_output = gr.Markdown(
                        label="ğŸ“š å½“å‰æ£€ç´¢æ–‡æ¡£"
                    )
                    
                    context_output = gr.Markdown(
                        label="ğŸ”„ ä¸Šä¸‹æ–‡å¤„ç†ä¿¡æ¯"
                    )
            
            # ç»‘å®šäº‹ä»¶
            multi_submit_btn.click(
                fn=rag_system.multi_turn_rag,
                inputs=[
                    multi_query_input,
                    chatbot,
                    multi_retrieval,
                    multi_top_k,
                    multi_model
                ],
                outputs=[
                    chatbot,
                    multi_docs_output,
                    context_output
                ]
            ).then(
                fn=lambda: "",
                outputs=multi_query_input
            )
            
            multi_query_input.submit(
                fn=rag_system.multi_turn_rag,
                inputs=[
                    multi_query_input,
                    chatbot,
                    multi_retrieval,
                    multi_top_k,
                    multi_model
                ],
                outputs=[
                    chatbot,
                    multi_docs_output,
                    context_output
                ]
            ).then(
                fn=lambda: "",
                outputs=multi_query_input
            )
            
            clear_btn.click(
                fn=rag_system.clear_history,
                outputs=[chatbot, multi_docs_output, context_output]
            )
        
        # ========== Tab 3: ç³»ç»Ÿä¿¡æ¯ ==========
        with gr.Tab("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"):
            gr.Markdown(
                """
                ## ç³»ç»ŸåŠŸèƒ½è¯´æ˜
                
                ### ğŸ“ å•è½®é—®ç­”
                - æ”¯æŒå¤šç§æ£€ç´¢æ–¹æ³•ï¼šç¨€ç–æ£€ç´¢ï¼ˆBM25, TF-IDFï¼‰ã€å¯†é›†æ£€ç´¢ï¼ˆE5, BGE, GTEï¼‰ã€å¤šå‘é‡æ£€ç´¢ï¼ˆColBERTï¼‰
                - å¯é€‰æ‹©ä¸åŒçš„Qwen2.5ç”Ÿæˆæ¨¡å‹
                - **Feature B**: å¯ç”¨"æ˜¾ç¤ºä¸­é—´æ¨ç†è¿‡ç¨‹"å¯æŸ¥çœ‹æŸ¥è¯¢é‡å†™ã€æ¨ç†æ­¥éª¤ç­‰
                
                ### ğŸ’¬ å¤šè½®å¯¹è¯
                - **Feature A**: æ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¤šè½®å¯¹è¯
                - è‡ªåŠ¨è¿½è¸ªå¯¹è¯å†å²å’Œå®ä½“
                - å°†åç»­é—®é¢˜é‡æ„ä¸ºç‹¬ç«‹æŸ¥è¯¢
                
                ### ğŸ¯ è¯„åˆ†é¡¹è¦†ç›–
                
                #### åŸºç¡€è¦æ±‚ âœ…
                - âœ… ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
                - âœ… æ˜¾ç¤ºæ£€ç´¢æ–‡æ¡£
                - âœ… å±•ç¤ºç”Ÿæˆç­”æ¡ˆ
                - âœ… æ¸…æ™°æ˜“è¯»çš„å¸ƒå±€
                
                #### åŠ åˆ†é¡¹ â­
                - â­ æ˜¾ç¤ºä¸­é—´æ¨ç†æ­¥éª¤ï¼ˆæŸ¥è¯¢é‡å†™ã€å­é—®é¢˜åˆ†è§£ã€è‡ªæˆ‘æ£€æŸ¥ï¼‰
                - â­ æ”¯æŒå¤šè½®å¯¹è¯äº¤äº’
                - â­ ä¸Šä¸‹æ–‡å¤„ç†ä¿¡æ¯å±•ç¤º
                
                ## æŠ€æœ¯æ ˆ
                - **å‰ç«¯æ¡†æ¶**: Gradio
                - **æ£€ç´¢æ–¹æ³•**: BM25, TF-IDF, E5, BGE, GTE, ColBERT
                - **ç”Ÿæˆæ¨¡å‹**: Qwen2.5 ç³»åˆ—
                
                ## å¼€å‘å›¢é˜Ÿ
                COMP5423 - Group X
                """
            )
    
    return demo


# ============================================================================
# å¯åŠ¨ç•Œé¢
# ============================================================================
if __name__ == "__main__":
    demo = create_rag_interface()
    demo.launch(
        share=False,  # è®¾ç½®ä¸ºTrueå¯ç”Ÿæˆå…¬å¼€é“¾æ¥
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True
    )